[
  {
    "path": "posts/2021-06-07_ssc2021/",
    "title": "My first Statistical Society of Canada Annual Meeting",
    "description": "Notes and links from SSC2021. I often find I get the most from conferences if I take notes with the vague notion of sharing them. So this is mostly for me, but I hope it might be of interest to others, too. Note: This post will be updated sporadically.",
    "author": [
      {
        "name": "Liza Bolton",
        "url": {}
      }
    ],
    "date": "2021-06-07",
    "categories": [
      "conferences",
      "stats-ed"
    ],
    "contents": "\n\nContents\nTalks you should go to (very biased recommendations)\nIndependent Summer Statistics Community (ISSC): Building a sustainable online undergraduate student community with Cocurricular Activities and Experiential Learning Opportunities\nThe Development and Implementation of a Toolkit for Learning R at all Levels.\n\nTalk notes\nInvited Presidential Address: Probability, Statistics, and Murder\nData privacy in official statistics (Panel Session)\nmverse: An R Library for Teaching and Conducting Multiverse Analysis\nIndependent Summer Statistics Community (ISSC): Building a sustainable online undergraduate student community with Cocurricular Activities and Experiential Learning Opportunities\nOnline Homework Impact in an Introductory Statistics Course\nTactile Response Experimental Analysis Toolkit (TREAT)\nQ&A for Statistical Education 2 session\nCautiously Constructing Charts\nThe Case Against Explainable Artificial Intelligence and Machine Learning\nCloser Than They Appear: A Bayesian Perspective On Individual-Level Heterogeneity In Risk Assessment\nOn the Use of Auxiliary Variables in Multilevel Regression and Poststratification\nSurvey Calibration via the Generalized-Method-of-Moments (GMM)\nAn initiative for promoting an inclusive, equitable and diverse environment at SSC\nA Gentle Introduction to the Poisson Process for a Third Year Probability Course\nThe Development and Implementation of a Toolkit for Learning R at all Levels\nDeveloping and Revising the Student Survey of Motivational Attitudes Toward Statistics: Results from a Pilot Study\nUsing a “Midterm Warning System” to Improve Student Performance and Engagement in an Introductory Statistics Course: An ongoing RCT Study\nData Science and Analytics Section Workshop\n\nReading list\nBooks\nArticles\n\n\n\n\n\nFigure 1: SSC 2021 Conference banner. Image description: Map of Canada with pink to red gradient from west to east on a black background. Test in top right says 2021 Annual Meeting - Virtual in English and French. All on black background.\n\n\n\n My SSC profile\nTalks you should go to (very biased recommendations)\nIndependent Summer Statistics Community (ISSC): Building a sustainable online undergraduate student community with Cocurricular Activities and Experiential Learning Opportunities\n 1:45 PM - 2:00 PM EDT on Monday, June 7\n Event link\n Nathalie Moon\nAbstract\nIn response to disruptions to our students’ plans due to COVID-19 and widespread feelings of isolation, we built a virtual community to help our students build portfolios, meet peers, and explore careers. In all, over 700 students in our programs signed up, and among the 164 students who responded to our end-of-summer survey, 41% were active and 48% passive participants; our data suggests that even passive participation was beneficial in making students feel more connected. As part of the ISSC, we held formal and informal data science workshops, social events, and career-building activities culminating in a DataFest COVID-19 Virtual Challenge. In all, 92 eligible teams applied to participate in DataFest, 62 were invited to compete, and 42 submitted complete submissions. In this talk, we will outline the principles guiding how the ISSC was structured including practical advice and tips for building a sustainable community, lessons learned, and plans for 2021.\nRésumé\nEn réponse aux perturbations des plans des élèves en raison de la COVID-19 et au sentiment d’isolement généralisé, nous avons créé une communauté virtuelle pour aider les étudiants à monter leur portfolio, à rencontrer leurs pairs et à découvrir des carrières. En tout, plus de 700 étudiants se sont inscrits à nos programmes et, parmi les 164 étudiants qui ont répondu à notre enquête de fin d’été, 41 % étaient des participants actifs et 48 % des participants passifs. Nos données suggèrent que même la participation passive a été bénéfique en donnant aux étudiants le sentiment d’être plus connectés. Dans le cadre de la Communauté statistique indépendante d’été, nous avons organisé des ateliers formels et informels sur les sciences des données, des événements sociaux et des activités de développement de carrière, qui ont débouché au défi virtuel des données DataFest COVID-19. Au total, 92 équipes admissibles ont posé leur candidature pour participer à ce défi, 62 ont été invitées à concourir et 42 ont soumis des dossiers complets. Dans cet exposé, nous présenterons les principes qui ont guidé la structure de la Communauté statistique indépendante d’été, les conseils pratiques et les astuces qui ont contribué à créer une communauté durable, ainsi que les leçons apprises et nos plans pour 2021.\nThe Development and Implementation of a Toolkit for Learning R at all Levels.\n 3:45 PM - 4:00 PM EDT on Wednesday, June 9\n Event link\n Samantha-Jo Caetano\nAbstract\nStatistics and data science have become ubiquitous in the hard and social sciences. When working with large data or complex methodology it is crucial that the data analysts are able to program. R is a statistical programming language that is free and popular in the statistics community. R works well for data visualizations, wrangling and employing simple to complex methodology. As educators in statistics we noticed a variation of programming backgrounds in our senior students. Our team of 7 undergraduate students, 2 graduate students, and 2 assistant professors have developed a toolkit to help students improve their programming in R. The toolkit is a set of interactive modules that students complete autonomously. The modules start from the very basics of installing R to tidyverse to employing Bayesian methods. In this talk, we will outline the development and uses of this toolkit, and highlight some next steps.\nRésumé\nLes statistiques et les sciences des données sont devenues omniprésentes dans les sciences dures et humaines. En travaillant avec des données volumineuses ou des méthodologies complexes, il est primordial que les analystes de données soient capables de programmer. R est un langage de programmation gratuit et populaire au sein de la communauté statistique. Il fonctionne à merveille pour les visualisations de données, leur préparation préalable et l’adoption de méthodologies simples ou complexes. En tant qu’éducateurs en statistique, nous avons remarqué que les formations en programmation varient parmi nos étudiants de cycle supérieur. Notre équipe de sept étudiants de premier cycle, deux étudiants de cycle supérieur et deux professeurs assistants ont conçu une boîte à outils afin d’aider les étudiants à rehausser leurs aptitudes de programmation en R. La boîte à outils est composée d’un ensemble de modules interactifs que les étudiants terminent de façon autonome. Les modules commencent par la base de l’installation de R, puis progressent vers tidyverse jusqu’à l’emploi de méthodes bayésiennes. Lors de cet exposé, nous décrirons les grandes lignes du développement et de l’utilisation de cette boîte à outils, et soulignerons les étapes à venir.\nTalk notes\nNotes and reflections of varying quality from the talks I attended + resources shared.\nNote: If I’ve written about talk and there is anything you’d like me to correct or add, please just let me know! Twitter/email links in the navigation bar.\nInvited Presidential Address: Probability, Statistics, and Murder\n Jeffrey Rosenthal,  @ProbabilityProf\nJeff took us on a journey through his experiences with media and especially as an expert witness in court cases. There are a mish-mash of links below and much more on his website: http://probability.ca.\nAn example of a case that was especially interesting/surprising was when he was an expert witness in a case about a marijuana grow-op. This story was really neat because significant jail time rests on whether or not the number of plants was more or less than 500. More than 500 leads to a mandatory three-year jail term.\nThe level of aggressive attacks you end up facing as a expert witness sounds extremely off-putting! I’m glad Jeff’s skin is think enough to go out and do this kind of work, because mine certainly is not.\nSome of Jeff’s final notes and advice:\nStatisticians are nicer, especially Canadian ones.\nBe cautious about what consulting work you agree to, especially in an adversarial context.\nYou can get paid a lot. Think about whether you want to you negotiate an hourly or fixed rate.\nThere are lots of satisfying/important aspects, but also lots of annoying/unpleasant ones, too.\n“If we statisticians don’t do it, then who will?”\nLinks\nHere are several links that were referred to during that talk or shared in chat. (Not exhaustive.)\nLottery link: http://probability.ca/lotteryscandal/\nAnnals Quadfecta: https://imstat.org/2021/05/14/the-annals-quadfecta-23/\nJeff’s Canadian Supreme Court opinion writing article: http://probability.ca/jeff/ftpdir/SCC_UTLJ.pdf\nDiscussion of SIDS/SUDI case history: https://en.wikipedia.org/wiki/Sally_Clark\n“The Clark case has its Aussie version that continues as Jeff speaks.” - Grace Chiu https://www.seattletimes.com/seattle-news/health/australian-mom-convicted-of-killing-4-children-seeks-pardon/\n\nwww.probability.ca/justice\nData privacy in official statistics (Panel Session)\n Donald Estep, Canadian Statistical Sciences Institute and Simon Fraser University,  @donestep1\n Natalie Shlomo, University of Manchester\n John Eltinge, US Census Bureau\n Anne-Sophie Charest, Université Laval\n Pierre Desrochers, Statistics Canada\nPeople don necessarily understand what their own views on disclosure/privacy look like mathematically.\nWhat is inference vs what is disclosure.\nUniqueness: if you publish something that is unique to one person, that is disclosure and that is fairly well agreed upon. BUT, what about as is scales up? What features makes these different, in context?\nWhat ‘privacy’ is interpreted as is context dependent, and expressed through jurisdictional law.\nSynthetic data generates new data by random draws from predictive models.\nDifferential privacy is a “perturbation tool”, a way to add noise/misclassify probabilistically.\nA wider ethical consider in this area is the question of which predictions are intrusions in unacceptable ways. This is more of an ethical/philosophical. When should we not make inferences?\nHow can we learn from others who have been doing risk communication (e.g., around health) to improve our own practices in official statistics\nMy background is using official statistics for social and health research in Aotearoa New Zealand, so it was excellent to dip a toe back into this world and hear about the context here.\nBig thanks to CANSSI for supporting this panel.  @CANSSIINCASS\nLinks\nDuncan, George & Keller-McNulty, Sallie & Stokes, Lynne. (2001). Disclosure Risk vs. Data Utility: The RU Confidentiality Map. https://www.researchgate.net/publication/245939728_Disclosure_Risk_vs_Data_Utility_The_RU_Confidentiality_Map\nKaloskampis. (2019). Synthetic data for public good. https://datasciencecampus.ons.gov.uk/projects/synthetic-data-for-public-good/\nNear, Darais & Boeckl. (2020). Differential Privacy for Privacy-Preserving Data Analysis: An Introduction to our Blog Series. https://www.nist.gov/blogs/cybersecurity-insights/differential-privacy-privacy-preserving-data-analysis-introduction-our\nmverse: An R Library for Teaching and Conducting Multiverse Analysis\n Michael Moon, University of Toronto,  @micbonmoon\nMotivating example, you’ll get different conclusions based on the choice to keep or remove an outlier when investigating hurricane names and people’s response (question: do people take hurricane’s less seriously if they have a feminine name?).\nFamiliar verbs from dplyr, removes need to do a bunch of error prone copy and pasting (systematic).\nInteractive modules are being developed by the team. Great demo of a Shiny app for playing with the hurricane data.\nSubmitting to CRAN sometime this summer.\nGreat presentation from Michael, and I’m super excited about playing with this package!\nLinks\nSlides: http://www.utstat.utoronto.ca/~moon/mverse-ssc21/#1\nPackage on GitHub: https://github.com/mverseanalysis/mverse\nSteegen S, Tuerlinckx F, Gelman A, Vanpaemel W. Increasing Transparency Through a Multiverse Analysis. Perspectives on Psychological Science. 2016;11(5):702-712. doi:10.1177/1745691616658637 https://journals.sagepub.com/doi/10.1177/1745691616658637\nIndependent Summer Statistics Community (ISSC): Building a sustainable online undergraduate student community with Cocurricular Activities and Experiential Learning Opportunities\n Nathalie Moon, University of Toronto\nI was part of the ISSC team, so not notes, other than I think Nathalie did a fab job explaining it.\nUnofficial list of Canadian universities doing ASA DataFest: U of T, UBC, Waterloo, MacEwan/University of Alberta — we should all be friends!\nLinks\nSlides (pdf)\n2020 TidyTuesday activities on GitHub: https://github.com/elb0/ISSC\nOnline Homework Impact in an Introductory Statistics Course\n Tharshanna Nadarajah, University of Toronto\nNeat intro to MyOpenMath advantages and how Tharshanna has used it in teaching, student response and outcomes.\nLinks\nMyOpenMath: https://www.myopenmath.com\nTactile Response Experimental Analysis Toolkit (TREAT)\n Sohee Kang, University of Toronto\nSome lovely data collection activities that students can do in class from a phone or computer. Love this from the abstract: “Students often feel disengaged with data that they do not perceive as being”real\" or “authentic”, and it is important that they believe that the data they are analyzing is representative of real-world problems.\"\nLinks\nMovement breaks that can be used in experiments https://ocw.utoronto.ca/movement-breaks/\nQ&A for Statistical Education 2 session\nLot’s of support for using Slack, though size/licensing can be challenging in large courses or with institution policy. Used for the Independent Summer Statistics Community and TA management by some courses at U of T.\nCourse emails are extremely helpful! E.g., sta303@utoronto.ca. Add a communication policy to your syllabus about where to go for what. We say course email is only for personal/private matters and everything else should be done via Piazza, e.g., “How many pages should this assignment be?”, “What’s a likelihood ratio test?” etc.\nCautiously Constructing Charts\n Michael Correll, Tableau\n“We’re just making bar charts, what’s ethically laden about that!” *sarcasm intensifies*\nTypes of bad visualizations: deceptive, fragile, bullshit 1, evil\nLoved the example of the when bar charts should start at 0, but how this ‘rule’ is a major issue when you try to show line graphs of global temperature and demonstrate the serious increases.\nSo, when IS it okay to truncate the y-axis? The camps Michael identifies are: the anathemists, the line chart exceptionists, the signalers (be really explicit about truncation!). The things is, there hasn’t really be testing of effectiveness in any of this.\nFurther research suggests that rule following isn’t going to cut it! The context of the charts AND the intent are very important.\n\nThere are multiple places in the pipeline where things can go wrong, but this means there are places for us to intervene!\nThe environment is curated to data which is wrangled to prepared data which is visualized to get an image and that image is read by someone to get a message. (Michael has a nice image to go with this in his slides.)\n\nAny human-computer interaction assistance project eventually just becomes Clippy.\nLinks\nhttps://accidental-art.tumblr.com/\nFrankfurt. (1986). On bullshit. http://www2.csudh.edu/ccauthen/576f12/frankfurt__harry_-_on_bullshit.pdf\nMcNutt, Kindlmannn & Correll. (2020). Surfacing Visualization Mirages https://arxiv.org/abs/2001.02316\nCorrell. (2018). Ethical Dimensions of Visualization Research. https://arxiv.org/pdf/1811.07271.pdf ) if that helps.\nThe Case Against Explainable Artificial Intelligence and Machine Learning\n Boris Babic, INSEAD but soon to be U of T\nWhite box (like a good ol’ GLM that is easy for a human to understand) vs a black box (e.g., deep learning models), but of course there is lots of potential for grey boxes, like how many parameters is too many? What about level of understanding of the user?\nExplainable vs interprettable\n‘Ersatz understanding’: in law/philosophy the idea of understanding is based in the ‘why’ between input and output.\nWhy isn’t this genuine understanding? Example given of post-hoc judge’s assistant noticing a pattern and saying that is why a decision was made for denying parole, when really there could be other reasons. The assistant is the white box approximation, but the judge is the black box. ‘Pseudo-understanding’.\n\nWe want explainable systems because this is tied to our ideas around accountability and trust.\nWe also want robustness (e.g., we’d expect similar advice for similar patients in a health context). White box approximations can give us a sense of ocal faithfulness but the potential to produce super different outcomes.\nIn summary, the main issues are pseudo/ersatz understanding—we have a false impression that we do understand what the black box is doing, the potential for non-stability when trying to use approximations, and the challenges due to existing issues with statistical literacy of data product users. Assumptions about causality, etc.\nLinks\nThanks to Jim Stallard for recommending Data Visualization: Charts, Maps, and Interactive Graphics by Robert Grant https://www.goodreads.com/book/show/40684954-data-visualization\nBoris and collaborators have a paper coming out in this topic. Keep an eye on his website: https://borisbabic.com/research/\nCloser Than They Appear: A Bayesian Perspective On Individual-Level Heterogeneity In Risk Assessment\n Kristian Lum, UPenn,  @KLDivergence\nKristian is so cool and I love any and every opportunity to hear her speak!\nThis presentation is introducing a new project around failure-to-appear in criminal processes.\nFAT/FACT/FATE (algorithmic fairness acronyms)\nThere are differences between ideas of GROUP fairness and INDIVIDUAL fairness (“people who are similar should be treated similarly”). Kristian found that this was already being discussed in the risk assessment literature but in a different way. Group probabilities and uncertainty around group-wise rates.\n“People are certainly more than the weighted sum of their covariates”\nWe tend to have to make the assumption, if we’re only observing each person once, that their individual probability will be approximated by the group probability. This feels naughty.\nWhat about when you DO have multiple observations per person? Well, it allows us to “take seriously” the idea that each person should only be judged on their own actions. When using group probabilities, you are being ‘judged’ through the actions of others.\nIn this project they are looking at using Bayesian random effects distributions and testing with a large Kentucky dataset. This tends to show us that we’re in the ‘large variance’ situation where people are not closely grouped around their group mean.\nRisk assessments affect the trajectory of real people’s lives.\nLinks\nAngwin, Larson, Mattu & Lauren Kirchner. (2016). ProPublica. Machine Bias. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\nOn the Use of Auxiliary Variables in Multilevel Regression and Poststratification\n Yajuan Si, University of Michigan,  @yajuansi\nMRP (“mister P”) is multilevel regression (MR) and poststratification (P)\n“A model-based perspective of poststratification”, Gelman and motivated by Little (1993)\nProposed as a combo of modelling and design.\nRooted in survey research but also modelling and has strong assumption, reliance on auxillary variables.\nFewer auxiliary, the better BUT it may violate conditional independence assumptions about cells. When constructing cells should use variables highly correlated with the outcome.\n“Shrinking from both sides”.\n\n\n\nFigure 2: List of papers about MRP authored by Si and colleagues\n\n\n\nLinks\nLittle. (1993). Post-Stratification: A Modeler’s Perspective. https://escholarship.org/uc/item/4np24519\nSee list of papers above\nSurvey Calibration via the Generalized-Method-of-Moments (GMM)\n Heng Chen, Bank of Canada\nMotivation: reports that people were concerned about transmission of COVID-19 via cash.\nConsumer surveys to understand how people were using cash in response to the pandemic. April, July and November 2020. Interested in changes between first and second waves.\nThree main variables of interest: Cash on hand, what proportion of people are using cash, what proportion of people plan to go cashless.\nHave repeated cross-sections and longitudinal data.\nFor cross-sectional data, considering propensity score, selection into surveys. Then can condition on Y on selection in to the given survey. Compare \\(Y_1 | S_I\\) with \\(Y_2|S_2\\)\nFor longitudinal, there is another ‘propensity’, that is to stay in both surveys, as well as the selction into the two survey waves.\n“covariate balancing”, propensity scoring has two jobs: modelling the choice and balance between weighted sample and unbiased targets. The weight (with the PS) is what helps up balance the observed value to the unbiased target.\nAdvantages of covariate balancing propensity scores: calibrated weights dual problem, “robust to (parametric) misspecification”, can use GMM (stacking moments to get other parameters), flexible about the unbiased targets.\nFirst, choose the covariates for the PS - they will be your denominator for the moment calculation. Second, get functional forms for the propensity scores for the selection into each survey and attrition measure (for longitudinal).\nResults for the cash research: Some decrease in cash on hand, but increase in having used cash and\nLinks\nChen et al. (2020). Cash and COVID-19: The impact of the pandemic on demand for and use of cash. https://www.bankofcanada.ca/wp-content/uploads/2020/07/sdp2020-6.pdf\nAn initiative for promoting an inclusive, equitable and diverse environment at SSC\nNothing specific to say other than how glad I am that SSC and NSERC and CANSSI and partner institutions are committed to improving EDI.\n Folks to follow: @BouchraNasri, @donestep1, @statacake, @alejandroadem\nA Gentle Introduction to the Poisson Process for a Third Year Probability Course\n Lengyi Han, UBC\nHan proposes that the usual ways of introducing Poisson processes and notation can be quite difficult for students, especially to connect to real world examples.\nMotivation with a Bernoulli process example (arrivals at a bank)\nSuppose we divide the time in question (say 60 minutes) into equal sub-intervals and a person can only arrive at the midpoint of a sub-interval.\nIf we make finer and finer sub-intervals we show that the Poisson and Bernoulli process will be approximately the same for sufficiently large \\(n\\).\nAfter the above, reiterate the assumptions and conditions for a Bernoulli process. From here, students can see that as the interval width tends to 0, we get the Poisson dist.\nSpecifically, the Bernoulli procress avoids the use of \\(o(h)\\) notation and student work through the derivation, motivating the use of this notation as helpful instead of obscure.\nUse Taylor expansion\n\nLinks\nLawerence Leemis on YouTube https://www.youtube.com/channel/UCoXVQ0xV2VOk3XrREv5061w\nThe Development and Implementation of a Toolkit for Learning R at all Levels\n Sam Caetano (presenting), University of Toronto  @StatisticalSam\n Also check out: @RohanAlexander, @michaelycchong, @pailfodgetts\nThis was an awesome example of a large team education innovation project! 2 faculty leads, 2 graduate students and 8 undergraduate students (+support from the department)\nStudents learned a lot about GitHub and collaboration as part of their RA roles.\nThere are introductions for complete beginners and it is also very ‘jump-in-able’ for folks who are already some of the way there.\nSuggested implementation: could have quiz questions in class quizzes related to the\nLinks\nToolkit home page: https://dosstoolkit.com/\nRead the paper! https://arxiv.org/abs/2105.09347\nlearnr package is great for creating interactive tutorials: https://rstudio.github.io/learnr/\nDeveloping and Revising the Student Survey of Motivational Attitudes Toward Statistics: Results from a Pilot Study\n Douglas Whitaker, Mount Saint Vincent University  @DouglasWhitaker\nS-SOMAS: Student Survey of MOtivational Attitude toward Statistics\nOne of family of 6 instruments. 2 x topics (statistics, data science) across 3 x types (student, instructor and environment)\nMASDER: Motivational Attitudes in Statistics and Data Science Education Research team\n“Expectancy-Value Theory”: achievement-related choices and performance are affected by what you value and what you expect to happen. EVERYTHING else operate through one or both of these.\nUse PCA, check the loadings/dimensionality before item response theory.\nExample given of ‘who can do stats’ vs ‘overall difficulty’ on the ‘difficult’ scale. The two ‘who can do’ items looks different to the others.\nSaw some substantial misfit\neRm package (Mair et al., 2021), mirt package (Chalmers, 2012) for generalized partial credit.\n\nI’m looking forward to seeing how these tools develop!\nUsing a “Midterm Warning System” to Improve Student Performance and Engagement in an Introductory Statistics Course: An ongoing RCT Study\n Nooshin Rotondi, Ontario Tech University\nBackground: intro stats for health care students, ‘have to’ be there as opposed to choosing statistics\nMeasured demographics, response on scale and performance\nRCT with two groups, intervention (personalized email) vs control (no personalized email, as per standard practice)\nAll resources mentioned in personalized emails had been previously shared with the whole class as part of standard practice.\nLoved this talk! Excited to see next steps.\nLinks\nDeslauriers et al. (2012). Transforming the Lowest-Performing Students: An Intervention That Worked. https://www.sei.ubc.ca/bitstream/seima/2141/1/Harris_Intervention_JCST2012.pdf\nGordanier, Hauk & Sankaran. (2019). Early intervention in college classes and improved student outcomes. https://www.sciencedirect.com/science/article/abs/pii/S0272775718305272\nData Science and Analytics Section Workshop\n Chris Holdgraf, 2i2c.org,  @choldgraf\n\nAn article about computational science in a scientific publication is not the scholarship itself, it is merely advertising of the scholarship. The actual scholarship is the complete software development environment and the complete set of instructions which generated the figures.\n~ Buckheit and Donoho\nWaveLab and Reproducible Research, 1995\n\n“Jupyter and the last mile problem”\n“Jupyter is a community of people and an ecosystem open tools and standard for interactive computing”\nLanguage agnostic: “empower people to use open tools”\nMetaphor of getting you to a coffee shop: walk? pay someone to drive you? use public infrastructure?\nWhat Chris would prefer (for himself and us all) is the public option!\nTake this idea and apply it to creating a great technical report.\n\nThe notebook experience combines a document standard, and environment (R, Python, etc.), and an interface.\nNotebooks are “structured but generic”. The can have many different front ends, for example:'classic’, JupyterLab and nteract.\nJupyterLab is meant to provide a more flexible and customizable space. It is sandalone as a UI, but you can also put components together, Lego-style into the UI you need.\nReal-time collaboration is being worked on!! Still an early prototype, but I am so excited.\nJupyter Book and MyST (pronounced ‘mist’)\nMarkdown is usually not extensible, but MyST lets you set out roles and directives. Can add images and include references.\nWant JupyterHub for a small user base (2-80 people)? The Littlest JupyterHub (tljh.jupyter.org). For larger groups, JupyterHub on Kubernetes.\nData8.org / inferentialthinking.org\nWe’ve been using JupyterHub in teaching at U of T for almost a year now, and it has been working really well. I use it with R and it also allows us to use RStudio which is really nice. Big thanks to Nathan Taback who has been leading this from our side, and to the members of 2i2c.org that have been helping us. Highly recommend.\nI really like Chris’ emphasis on design principles in this talk.\nThe rest of the session was hand on workshops from David Liu, Nathan Taback ( @NathanTaback) and Nathaniel Stevens. https://github.com/ssc-datascience/pythonjupyter_wshop2021 They were really good!\nLinks\nChris Holdgraf’s personal website: https://predictablynoisy.com/\nJupyter https://jupyter.org/ and JupyterHub https://jupyter.org/hub\nhttps://2i2c.org/ (Chris is Director)\nBinder https://mybinder.org/\nJupyterBook for publishing https://jupyterbook.org (like bookdown, cool!)\nGorgeous images from Scriberia about data work: https://zenodo.org/record/3332808\nPangeo https://pangeo.io a community platform for Big Data geoscience\nReading list\nBooks\n Goodreads shelf for SSC2021\nKnock on Wood: Luck, Chance, and the Meaning of Everything by Jeffrey S. Rosenthal https://www.goodreads.com/book/show/36300756-knock-on-wood\nData Visualization: Charts, Maps, and Interactive Graphics by Robert Grant https://www.goodreads.com/book/show/40684954-data-visualization\nArticles\nJeff’s Canadian Supreme Court opinion writing article: http://probability.ca/jeff/ftpdir/SCC_UTLJ.pdf\nKaloskampis. (2019). Synthetic data for public good. https://datasciencecampus.ons.gov.uk/projects/synthetic-data-for-public-good/\nSteegen S, Tuerlinck F, Gelman A, Vanpaemel W. Increasing Transparency Through a Multiverse Analysis. Perspectives on Psychological Science. 2016;11(5):702-712. doi:10.1177/1745691616658637 https://journals.sagepub.com/doi/10.1177/1745691616658637\nMcNutt, Kindlmannn & Correll. (2020). Surfacing Visualization Mirages https://arxiv.org/abs/2001.02316\nCorrell. (2018). Ethical Dimensions of Visualization Research. https://arxiv.org/pdf/1811.07271.pdf ) if that helps.\nDeslauriers et al. (2012). Transforming the Lowest-Performing Students: An Intervention That Worked. https://www.sei.ubc.ca/bitstream/seima/2141/1/Harris_Intervention_JCST2012.pdf\n\nIn the sense of Frankfurt’s On Bullshit http://www2.csudh.edu/ccauthen/576f12/frankfurt__harry_-_on_bullshit.pdf↩︎\n",
    "preview": "posts/2021-06-07_ssc2021/images/SSCDesktopBannerMap.png",
    "last_modified": "2021-06-12T16:11:21-04:00",
    "input_file": {},
    "preview_width": 2560,
    "preview_height": 1170
  }
]
